{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "759SG4TyfbUn"
   },
   "source": [
    "#**Maestría en Inteligencia Artificial Aplicada**\n",
    "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
    "###Tecnológico de Monterrey\n",
    "###Prof Luis Eduardo Falcón Morales\n",
    "\n",
    "###Alumno: Salvador Martínez Morales\n",
    "###Matricula: A01273366\n",
    "\n",
    "## **Adtividad de la Semana 02**\n",
    "###**Introducción al procesamiento de texto.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ue1YAKx3XDo"
   },
   "source": [
    "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
    "\n",
    "MNA_NLP_semana_02_Actividad_datos.txt\n",
    "\n",
    "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ .\n",
    "\n",
    "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj-h4drXD-X9"
   },
   "source": [
    "#**Parte 1. Cargamos los datos.**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY6yifxscfrx"
   },
   "source": [
    "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios.\n",
    "\n",
    "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
    "\n",
    "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
    "\n",
    "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1714329992808,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "OJ26dAfhdFnf"
   },
   "outputs": [],
   "source": [
    "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
    "import re             # importamos re para el manejo de las expresiones regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19421,
     "status": "ok",
     "timestamp": 1714330014599,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "Ok8vCEI5f1-7",
    "outputId": "baec27b9-0562-43b2-e9ad-cc5463c0015c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1714330017667,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "QHUmJyjDdGNP"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Procesamiento de lenguaje natural/Semana 2/MNA_NLP_semana_02_Actividad_datos.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Procesamiento de lenguaje natural/Semana 2/MNA_NLP_semana_02_Actividad_datos.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# puedes actualizar la ruta a tu archivo, en dado caso.\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# abrimos el archivo en modo lectura.\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m     docs \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()    \u001b[38;5;66;03m# separamos cada comentario por líneas\u001b[39;00m\n\u001b[0;32m     10\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()  \u001b[38;5;66;03m# ya que tenemos la información en la variable docs, cerramos el archivo\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Procesamiento de lenguaje natural/Semana 2/MNA_NLP_semana_02_Actividad_datos.txt'"
     ]
    }
   ],
   "source": [
    "# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\n",
    "\n",
    "DIR = \"/content/drive/MyDrive/Procesamiento de lenguaje natural/Semana 2/MNA_NLP_semana_02_Actividad_datos.txt\"\n",
    "\n",
    "with open(DIR,        # puedes actualizar la ruta a tu archivo, en dado caso.\n",
    "          mode='r',     # abrimos el archivo en modo lectura.\n",
    "          ) as f:\n",
    "    docs = f.readlines()    # separamos cada comentario por líneas\n",
    "\n",
    "f.close()  # ya que tenemos la información en la variable docs, cerramos el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1714330018779,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "L6WzrSrodG-Y",
    "outputId": "6e96f3c6-ee13-46eb-c080-c7d967948b67"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mdocs\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m   \u001b[38;5;66;03m# Verifica que tu variable \"docs\" es una lista\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1714330019835,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "QIK1u9WS2FtS",
    "outputId": "c08e8134-074f-41c9-bceb-8eb27251bfcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1714330020816,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "9AMLIfQvJqNZ",
    "outputId": "bd60f0a5-3dae-4626-8ebe-18c04f747b81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wow... Loved this place.\\n',\n",
       " 'Crust is not good.\\n',\n",
       " 'Not tasty and the texture was just nasty.\\n',\n",
       " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n',\n",
       " 'The selection on the menu was great and so were the prices.\\n',\n",
       " 'Now I am getting angry and I want my damn pho.\\n',\n",
       " \"Honeslty it didn't taste THAT fresh.)\\n\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n',\n",
       " 'The fries were great too.\\n',\n",
       " 'A great touch.\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0:10]     # observa algunos de los primeros comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_ewoagic5jc"
   },
   "source": [
    "#**Parte 2: sección de preguntas (regex).**   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-eMJa3DFCIV"
   },
   "source": [
    "##**Instrucciones:**\n",
    "\n",
    "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
    "\n",
    "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78nJMemzn5a5"
   },
   "source": [
    "*   **Pregunta 1.**\n",
    "\n",
    "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario.\n",
    "\n",
    "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1714330063017,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "PwbYYIuZn8pE"
   },
   "outputs": [],
   "source": [
    "sin_saltos = []\n",
    "\n",
    "# Eliminación de los latos de línea en cada uno de los comentarios.\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      sin_saltos.append(re.sub(r'\\n', '', linea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1714330064658,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "j-0qeh2Jn8l1",
    "outputId": "81f1815a-a468-4b6c-d6aa-291c7e0a8e0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wow... Loved this place.',\n",
       " 'Crust is not good.',\n",
       " 'Not tasty and the texture was just nasty.',\n",
       " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       " 'The selection on the menu was great and so were the prices.',\n",
       " 'Now I am getting angry and I want my damn pho.',\n",
       " \"Honeslty it didn't taste THAT fresh.)\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
       " 'The fries were great too.',\n",
       " 'A great touch.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_saltos[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWeKQC93ctEo"
   },
   "source": [
    "*   **Pregunta 2.**  \n",
    "\n",
    "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\".\n",
    "\n",
    "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen.\n",
    "\n",
    "Indica cuántos resultados obtuviste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1714330110043,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "0p3kMXfddICc",
    "outputId": "ce806002-13e1-4042-855b-620b685a4ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La palabra 'If you want a sandwich just go to any Firehouse!!!!!\n",
      "' tiene 5 de signos de admiracion.\n",
      "La palabra 'This place receives stars for their APPETIZERS!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'All I have to say is the food was amazing!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'Best breakfast buffet!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'Sooooo good!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'Don't do it!!!!\n",
      "' tiene 4 de signos de admiracion.\n",
      "La palabra 'DELICIOUS!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'This is the place where I first had pho and it was amazing!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'Favorite place in town for shawarrrrrrma!!!!!!\n",
      "' tiene 6 de signos de admiracion.\n",
      "La palabra 'First - the bathrooms at this location were dirty- Seat covers were not replenished & just plain yucky!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra '\"Classy/warm atmosphere, fun and fresh appetizers, succulent steaks (Baseball steak!!!!!\"\n",
      "' tiene 5 de signos de admiracion.\n",
      "La palabra 'It was delicious!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'Best tacos in town by far!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'We loved the biscuits!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'Boy was that sucker dry!!.\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'Very disappointing!!!\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'Have been going since 2007 and every meal has been awesome!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra '2 Thumbs Up!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'A FLY was in my apple juice.. A FLY!!!!!!!!\n",
      "' tiene 8 de signos de admiracion.\n",
      "La palabra '\"I'm so happy to be here!!!\"\"\"\n",
      "' tiene 3 de signos de admiracion.\n",
      "La palabra 'This place is great!!!!!!!!!!!!!!\n",
      "' tiene 14 de signos de admiracion.\n",
      "La palabra 'It was packed!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra '\"Bad day or not, I have a very low tolerance for rude customer service people, it is your job to be nice and polite, wash dishes otherwise!!\"\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'The chips and sals a here is amazing!!!!!!!!!!!!!!!!!!!\n",
      "' tiene 19 de signos de admiracion.\n",
      "La palabra 'This place lacked style!!\n",
      "' tiene 2 de signos de admiracion.\n",
      "La palabra 'I was VERY disappointed!!\n",
      "' tiene 2 de signos de admiracion.\n"
     ]
    }
   ],
   "source": [
    "signo_admiracion = []\n",
    "\n",
    "#Búsqueda e impresión de todas las palabras que terminan con dos o más signos de admiración seguidos\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      if(re.findall(r'\\w+!{2,}', linea)):\n",
    "        cantidad = linea.count(\"!\")\n",
    "        signo_admiracion.append(linea)\n",
    "        print(f\"La palabra '{linea}' tiene {cantidad} de signos de admiracion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1714330126600,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "SPVM1MCWdH6Z",
    "outputId": "2babfb66-4e35-4d5a-fcd1-bb0c545d6fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadenas que terminan con dos o más signos de admiración seguidos:  26\n"
     ]
    }
   ],
   "source": [
    "#Total de palabras encontradas\n",
    "print(\"Cadenas que terminan con dos o más signos de admiración seguidos: \", len(signo_admiracion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-s3okBqL96TT"
   },
   "source": [
    "*   **Pregunta 3.**  \n",
    "\n",
    "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
    "\n",
    "Indica cuántas palabras encontraste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1714330148010,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "yKHJkZKo_nW5",
    "outputId": "4be25b4f-117c-4ac8-e8ba-6d4cfabd3f5f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m palabra_mayusculas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Palabras escritas por completo en mayúsculas\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mDIR\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m archivo:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m linea \u001b[38;5;129;01min\u001b[39;00m archivo:\n\u001b[0;32m      6\u001b[0m       palabras_array \u001b[38;5;241m=\u001b[39m (re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,}\u001b[39m\u001b[38;5;124m'\u001b[39m, linea))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DIR' is not defined"
     ]
    }
   ],
   "source": [
    "palabra_mayusculas = []\n",
    "\n",
    "#Palabras escritas por completo en mayúsculas\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      palabras_array = (re.findall(r'\\s{2,}', linea))\n",
    "      for palabra in palabras_array:\n",
    "        palabra_mayusculas.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1714330204558,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "L3q08aq69sNn",
    "outputId": "574998c9-3c4f-462d-c73d-52b9c2f61275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en mayusculas:  455\n"
     ]
    }
   ],
   "source": [
    "#Total de palabras encontradas\n",
    "print(\"Palabras en mayusculas: \", len(palabra_mayusculas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX8eYyDoMZma"
   },
   "source": [
    "*   **Pregunta 4.**  \n",
    "\n",
    "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas.\n",
    "\n",
    "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
    "\n",
    "Indica cuántos resultados obtuviste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1714330295337,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "K8VuZxvTMYj6"
   },
   "outputs": [],
   "source": [
    "comentarios_mayusculas = []\n",
    "\n",
    "#Comentarios escritos en su totalidad en mayúsculas\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      comentarios_array = re.findall(r'^#[A-Z\\s]+$', linea, re.MULTILINE)\n",
    "      for comentario in comentarios_array:\n",
    "        comentarios_mayusculas.append(comentario)\n",
    "        print(comentario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1714330296486,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "PmKgX7sCMcDx",
    "outputId": "fb04d115-5be7-4408-945a-508d2875c939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de comentarios encontrados:  0\n"
     ]
    }
   ],
   "source": [
    "#Número de comentarios en mayúsculas\n",
    "print(\"Número de comentarios encontrados: \",len(comentarios_mayusculas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1i6qv7-McmU"
   },
   "source": [
    "*   **Pregunta 5.**  \n",
    "\n",
    "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú.\n",
    "\n",
    "Indica cuántos resultados obtuviste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1714330308961,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "nZZ5zKUOMeGD",
    "outputId": "f2cc618a-23e5-4681-933f-99d4e5640a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiancé\n",
      "Café\n",
      "puréed\n"
     ]
    }
   ],
   "source": [
    "palabra_acentuada = []\n",
    "\n",
    "#Palabras acentuadas\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      acento = re.findall(r'\\b\\w*[áéíóú]\\w*\\b', linea, re.IGNORECASE)\n",
    "      for palabra in acento:\n",
    "        palabra_acentuada.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1714330322703,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "l1mFvUEZMe8s",
    "outputId": "bdbe3a03-b3ac-432c-90ef-92de70a84636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palabras acentuadas:  3\n"
     ]
    }
   ],
   "source": [
    "#Total de palabras acentuadas\n",
    "print(\"Número de palabras acentuadas: \",len(palabra_acentuada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmPiAI82Mfb3"
   },
   "source": [
    "*   **Pregunta 6.**  \n",
    "\n",
    "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$.\n",
    "\n",
    "Indica cuántos resultados obtuviste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1714330450247,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "6vhe9-Y-MhL9",
    "outputId": "4f368c08-b219-41c5-9693-eb97305b2124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ \n",
      "$ .00\n",
      "$ \n",
      "$ \n",
      "$ \n",
      "$ .85\n",
      "$ \n",
      "$ .99\n"
     ]
    }
   ],
   "source": [
    "palabras_monetarias = []\n",
    "\n",
    "#Cantidades numéricas monetarias\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      moneda = re.findall(r'\\$\\d+(\\.\\d+)?', linea)\n",
    "      for palabra in moneda:\n",
    "        palabras_monetarias.append(palabra)\n",
    "        print(\"$\",palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1714330451533,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "_t0a5xWDMhQ5",
    "outputId": "0f6316e8-7c0c-4cb9-9955-a0191d7bc1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de resultados encontrados: 8\n"
     ]
    }
   ],
   "source": [
    "#Total de cantidades numéricas\n",
    "print(\"Número de resultados encontrados:\", len(palabras_monetarias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2j-HpvhwMhq2"
   },
   "source": [
    "*   **Pregunta 7.**  \n",
    "\n",
    "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
    "\n",
    "Indica cuántos resultados obtuviste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1714330467348,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "kqqyRChVMjol",
    "outputId": "a5ab8db0-fc0c-42e9-ef5d-ce74f6429595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved\n",
      "loved\n",
      "Loved\n",
      "love\n",
      "loves\n",
      "LOVED\n",
      "lovers\n",
      "love\n",
      "lovers\n",
      "Love\n",
      "loved\n",
      "loved\n",
      "love\n",
      "love\n",
      "love\n",
      "loved\n",
      "love\n",
      "loved\n",
      "Love\n",
      "LOVED\n",
      "love\n",
      "lovely\n",
      "love\n",
      "lovely\n",
      "love\n",
      "lover\n",
      "loved\n",
      "love\n",
      "love\n",
      "love\n",
      "love\n",
      "love\n",
      "love\n",
      "love\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "palabra_love = []\n",
    "\n",
    "#Variantes de palabra Love\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      love = re.findall(r'\\blove\\w*\\b', linea, re.IGNORECASE)\n",
    "      for palabra in love:\n",
    "        palabra_love.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1714330481559,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "UXd0VQluMj_x",
    "outputId": "6e8a0b1a-195a-4489-99a8-4d2b7d7ec4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de resultados encontrados: 35\n"
     ]
    }
   ],
   "source": [
    "#Número de palabras variantes Love\n",
    "print(\"Número de resultados encontrados:\", len(palabra_love))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ctb-NTY3MkYG"
   },
   "source": [
    "*   **Pregunta 8.**  \n",
    "\n",
    "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good.\n",
    "\n",
    "Indica cuántas encontraste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1714330498960,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "A8Nf3B_cMlqg",
    "outputId": "f25c9bda-1519-412d-a2f6-1671be3c703e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "Sooooo\n",
      "good\n",
      "good\n",
      "Good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "Good\n",
      "good\n",
      "good\n",
      "soooo\n",
      "good\n",
      "Good\n",
      "good\n",
      "Good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "gooodd\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "Good\n",
      "good\n",
      "soooooo\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "Good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "soooo\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "palabra_so_good = []\n",
    "\n",
    "#Variantes so y good\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      so = re.findall(r'\\b[sS]+[oO]{2,}\\b', linea, re.IGNORECASE)\n",
    "      good = re.findall(r'\\bgoo+d\\w*\\b', linea, re.IGNORECASE)\n",
    "      total = so + good\n",
    "      for palabra in total:\n",
    "        palabra_so_good.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1714330516846,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "svS4-vvPMl6f",
    "outputId": "e67234b2-c400-47c8-c4d3-cb6dec9e2101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de resultados encontrados: 100\n"
     ]
    }
   ],
   "source": [
    "#Número total de palabras variantes so y good\n",
    "print(\"Número de resultados encontrados:\", len(palabra_so_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkak1opjMmlk"
   },
   "source": [
    "*   **Pregunta 9.**  \n",
    "\n",
    "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
    "\n",
    "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
    "\n",
    "Indica la cantidad de palabras encontradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1714330563875,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "PYxdp3uhMoD0",
    "outputId": "f1e24c6c-87f8-4613-ff0f-f0b37b3c6dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation\n",
      "recommended\n",
      "overwhelmed\n",
      "inexpensive\n",
      "establishment\n",
      "imaginative\n",
      "opportunity\n",
      "experiencing\n",
      "underwhelming\n",
      "relationship\n",
      "unsatisfying\n",
      "disappointing\n",
      "outrageously\n",
      "disappointing\n",
      "expectations\n",
      "restaurants\n",
      "suggestions\n",
      "disappointed\n",
      "considering\n",
      "Unfortunately\n",
      "immediately\n",
      "ingredients\n",
      "accommodations\n",
      "maintaining\n",
      "Interesting\n",
      "disrespected\n",
      "accordingly\n",
      "unbelievable\n",
      "cheeseburger\n",
      "descriptions\n",
      "inexpensive\n",
      "disappointed\n",
      "Veggitarian\n",
      "outstanding\n",
      "recommendation\n",
      "disappointed\n",
      "disappointed\n",
      "neighborhood\n",
      "disappointed\n",
      "corporation\n",
      "considering\n",
      "exceptional\n",
      "shawarrrrrrma\n",
      "disappointed\n",
      "vinaigrette\n",
      "immediately\n",
      "unbelievably\n",
      "replenished\n",
      "disappointed\n",
      "enthusiastic\n",
      "Outstanding\n",
      "comfortable\n",
      "interesting\n",
      "INCONSIDERATE\n",
      "considering\n",
      "transcendant\n",
      "disappointment\n",
      "disappointed\n",
      "disappointed\n",
      "overwhelmed\n",
      "professional\n",
      "Furthermore\n",
      "combination\n",
      "connoisseur\n",
      "profiterole\n",
      "outstanding\n",
      "acknowledged\n",
      "ventilation\n",
      "beautifully\n",
      "establishment\n",
      "extraordinary\n",
      "disappointed\n",
      "cheesecurds\n",
      "disappointed\n",
      "interesting\n",
      "experienced\n",
      "opportunity\n",
      "disgraceful\n",
      "restaurants\n",
      "ESTABLISHMENT\n",
      "recommended\n",
      "disappointed\n",
      "recommended\n",
      "acknowledged\n",
      "presentation\n",
      "Philadelphia\n",
      "disappointed\n",
      "disappointing\n",
      "grandmother\n",
      "drastically\n",
      "informative\n",
      "Disappointed\n",
      "constructed\n",
      "comfortable\n",
      "Smashburger\n",
      "cheeseburger\n",
      "neighborhood\n",
      "disappointed\n",
      "hospitality\n",
      "recommending\n",
      "disappointed\n",
      "deliciously\n",
      "compliments\n",
      "recommendation\n",
      "establishment\n",
      "calligraphy\n",
      "traditional\n",
      "combination\n",
      "Unfortunately\n",
      "Wienerschnitzel\n",
      "unfortunately\n",
      "considering\n",
      "highlighted\n",
      "Mediterranean\n",
      "unprofessional\n",
      "anticipated\n",
      "disappointing\n",
      "unexperienced\n",
      "disrespected\n",
      "professional\n",
      "restaurants\n",
      "Disappointing\n",
      "WAAAAAAyyyyyyyyyy\n",
      "reservation\n",
      "imagination\n",
      "undercooked\n",
      "disappointed\n",
      "disappointment\n",
      "disappointment\n",
      "deuchebaggery\n",
      "disappointed\n",
      "disappointment\n",
      "immediately\n",
      "Unfortunately\n",
      "disapppointment\n",
      "circumstances\n",
      "undercooked\n",
      "caterpillar\n",
      "presentation\n",
      "disappointed\n",
      "underwhelming\n"
     ]
    }
   ],
   "source": [
    "palabra_mayor_10 = []\n",
    "\n",
    "#Palabras con longitud mayor a 10 caracteres\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      mayor_10 = re.findall(r'\\b[A-Za-z]{11,}\\b', linea, re.IGNORECASE)\n",
    "      for palabra in mayor_10:\n",
    "        palabra_mayor_10.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1714330560589,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "BR7e2F4FMof-",
    "outputId": "8783ca1f-be87-44fa-8fc7-82a393ecc5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de resultados encontrados: 141\n"
     ]
    }
   ],
   "source": [
    "#Número de palabras con mayor a 10 caracteres\n",
    "print(\"Número de resultados encontrados:\", len(palabra_mayor_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApjTNzSxMpDc"
   },
   "source": [
    "*   **Pregunta 10.**  \n",
    "\n",
    "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string.\n",
    "\n",
    "Indica la cantidad de resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1714330599018,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "Vb0ndRGAMqdL",
    "outputId": "d44e346b-fd03-4c21-951c-d1ef8269d306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved\n",
      "May\n",
      "Rick\n",
      "Steve\n",
      "Cod\n",
      "Vegas\n",
      "Burrittos\n",
      "Blah\n",
      "Mexican\n",
      "Luke\n",
      "Our\n",
      "Hiro\n",
      "Firehouse\n",
      "Greek\n",
      "Greek\n",
      "Heart\n",
      "Attack\n",
      "Grill\n",
      "Vegas\n",
      "Dos\n",
      "Gringos\n",
      "Jeff\n",
      "Bad\n",
      "Customer\n",
      "Service\n",
      "Vegas\n",
      "Rice\n",
      "Company\n",
      "Hard\n",
      "Rock\n",
      "Casino\n",
      "Buffet\n",
      "Tigerlilly\n",
      "Thai\n",
      "Not\n",
      "Vegas\n",
      "Lox\n",
      "Subway\n",
      "Subway\n",
      "Vegas\n",
      "Vegas\n",
      "Mandalay\n",
      "Bay\n",
      "Great\n",
      "Phoenix\n",
      "Vegas\n",
      "Khao\n",
      "Soi\n",
      "Valley\n",
      "Phoenix\n",
      "Magazine\n",
      "Pho\n",
      "Fridays\n",
      "Tasty\n",
      "Jamaican\n",
      "Bisque\n",
      "Bussell\n",
      "Sprouts\n",
      "Risotto\n",
      "Filet\n",
      "Otto\n",
      "Yeah\n",
      "Not\n",
      "Also\n",
      "Vegas\n",
      "Greek\n",
      "Veggitarian\n",
      "Madison\n",
      "Ironman\n",
      "Pho\n",
      "Burger\n",
      "Pizza\n",
      "Salads\n",
      "They\n",
      "Bachi\n",
      "Service\n",
      "English\n",
      "Pizza\n",
      "Hut\n",
      "Seat\n",
      "Gold\n",
      "Standard\n",
      "Thai\n",
      "Tucson\n",
      "Vegas\n",
      "Chipotle\n",
      "Baseball\n",
      "Gordon\n",
      "Ramsey\n",
      "Steak\n",
      "Vegas\n",
      "Outstanding\n",
      "Best\n",
      "Food\n",
      "Lobster\n",
      "Bisque\n",
      "Vegas\n",
      "Eggplant\n",
      "Green\n",
      "Bean\n",
      "Halibut\n",
      "Vegas\n",
      "Vegas\n",
      "Crystals\n",
      "Aria\n",
      "Bouchon\n",
      "San\n",
      "Francisco\n",
      "Bay\n",
      "Area\n",
      "Buldogis\n",
      "Gourmet\n",
      "Hot\n",
      "Dog\n",
      "Vegas\n",
      "Camelback\n",
      "Flower\n",
      "Shop\n",
      "Cartel\n",
      "Coffee\n",
      "Las\n",
      "Vegas\n",
      "Bunch\n",
      "Noca\n",
      "Vegas\n",
      "Sat\n",
      "Sun\n",
      "Mexican\n",
      "Frenchman\n",
      "Perfect\n",
      "Vegas\n",
      "Palm\n",
      "Are\n",
      "This\n",
      "Thai\n",
      "Toast\n",
      "Phoenix\n",
      "North\n",
      "Scottsdale\n",
      "Bloody\n",
      "Mary\n",
      "Caesar\n",
      "Macarons\n",
      "Experience\n",
      "Very\n",
      "Disappointed\n",
      "Big\n",
      "Bay\n",
      "Plater\n",
      "Italian\n",
      "Vegas\n",
      "Ganoush\n",
      "Nobu\n",
      "Smashburger\n",
      "Panna\n",
      "Cotta\n",
      "Breeze\n",
      "Mango\n",
      "Magic\n",
      "Pineapple\n",
      "Delight\n",
      "The\n",
      "Steak\n",
      "Valley\n",
      "Cibo\n",
      "Up\n",
      "Pros\n",
      "Large\n",
      "Nice\n",
      "Great\n",
      "The\n",
      "Elk\n",
      "Filet\n",
      "Dylan\n",
      "All\n",
      "Han\n",
      "Nan\n",
      "Chicken\n",
      "Bar\n",
      "Edinburgh\n",
      "Chinese\n",
      "Indian\n",
      "Prices\n",
      "Phoenix\n",
      "Hot\n",
      "Sour\n",
      "Egg\n",
      "Flower\n",
      "Soups\n",
      "Stars\n",
      "Sunday\n",
      "The\n",
      "Pita\n",
      "Wienerschnitzel\n",
      "Maine\n",
      "Lobster\n",
      "Roll\n",
      "Maria\n",
      "Wife\n",
      "Everything\n",
      "Strip\n",
      "To\n",
      "Place\n",
      "Gyros\n",
      "Mediterranean\n",
      "Chicken\n",
      "Salad\n",
      "Mellow\n",
      "Mushroom\n",
      "Thai\n",
      "Vegas\n",
      "Mmmm\n",
      "Buffet\n",
      "Bellagio\n",
      "Vegas\n",
      "Christmas\n",
      "Eve\n",
      "Denny\n",
      "Vegetarian\n",
      "Taco\n",
      "Heimer\n",
      "Ha\n",
      "Long\n",
      "Bay\n",
      "Subway\n",
      "When\n",
      "Brushfire\n",
      "Ninja\n",
      "Sushi\n"
     ]
    }
   ],
   "source": [
    "palabra_mayuscula_minuscula = []\n",
    "\n",
    "#Palabras que inician con una letra en mayúscula y terminan con una minúscula\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      may_min = re.findall(r'\\b[A-Z][a-z]+\\b', linea)\n",
    "      for palabra in may_min[1:]:\n",
    "        palabra_mayuscula_minuscula.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1714330623062,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "dLPTRPnTMqqx",
    "outputId": "403bc245-1631-4ea3-e863-bf213465a40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de resultados encontrados: 229\n"
     ]
    }
   ],
   "source": [
    "#Número de palabras que inician con una letra en mayúscula y terminan con una minúscula\n",
    "print(\"Cantidad de resultados encontrados:\", len(palabra_mayuscula_minuscula))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7nfm4KhMrNW"
   },
   "source": [
    "*   **Pregunta 11.**  \n",
    "\n",
    "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
    "\n",
    "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían.\n",
    "\n",
    "Indica la cantidad de resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1714330642992,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "OwU-a7eGMsub",
    "outputId": "270275ac-3517-439c-ed7d-9bf9acbee2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat-lined\n",
      "hands-down\n",
      "must-stop\n",
      "sub-par\n",
      "Service-check\n",
      "in-house\n",
      "been-stepped\n",
      "in-and\n",
      "tracked-everywhere\n",
      "multi-grain\n",
      "to-go\n",
      "non-customer\n",
      "High-quality\n",
      "sit-down\n",
      "over-whelm\n",
      "low-key\n",
      "non-fancy\n",
      "golden-crispy\n",
      "over-priced\n",
      "over-hip\n",
      "under-services\n"
     ]
    }
   ],
   "source": [
    "palabra_guion = []\n",
    "\n",
    "#Palabras que están separadas por un guion, \"-\",\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      guion = re.findall(r'\\b\\w+-\\w+\\b', linea)\n",
    "      for palabra in guion:\n",
    "        palabra_guion.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1714330660118,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "SgzIL74ZMtGw",
    "outputId": "db1e1030-a405-46b0-dcda-4215762265ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de resultados encontrados: 21\n"
     ]
    }
   ],
   "source": [
    "#Número de palabras que están separadas por un guion, \"-\",\n",
    "print(\"Cantidad de resultados encontrados:\", len(palabra_guion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEIgl79HMthr"
   },
   "source": [
    "*   **Pregunta 12.**  \n",
    "\n",
    "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\".\n",
    "\n",
    "Indica la cantidad de palabras que encontraste de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1714330673704,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "I4TSofBMMv9y",
    "outputId": "f0ccd6a2-c3db-466d-b740-9546a2cb01d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved\n",
      "Stopped\n",
      "loved\n",
      "during\n",
      "getting\n",
      "being\n",
      "ended\n",
      "overpriced\n",
      "being\n",
      "tried\n",
      "disgusted\n",
      "shocked\n",
      "recommended\n",
      "amazing\n",
      "performed\n",
      "red\n",
      "asked\n",
      "overwhelmed\n",
      "running\n",
      "redeeming\n",
      "grossed\n",
      "melted\n",
      "getting\n",
      "provided\n",
      "thing\n",
      "cooked\n",
      "dressing\n",
      "refreshing\n",
      "ordered\n",
      "realized\n",
      "running\n",
      "Loved\n",
      "lined\n",
      "cooked\n",
      "ripped\n",
      "ripped\n",
      "petrified\n",
      "amazing\n",
      "included\n",
      "expected\n",
      "nothing\n",
      "appalling\n",
      "seasoned\n",
      "cheated\n",
      "wasting\n",
      "eating\n",
      "going\n",
      "Coming\n",
      "experiencing\n",
      "underwhelming\n",
      "walked\n",
      "smelled\n",
      "eating\n",
      "tailored\n",
      "raving\n",
      "spring\n",
      "unsatisfying\n",
      "amazing\n",
      "Everything\n",
      "disappointing\n",
      "dining\n",
      "flirting\n",
      "arrived\n",
      "roasted\n",
      "added\n",
      "thing\n",
      "coming\n",
      "cooked\n",
      "playing\n",
      "passed\n",
      "ordering\n",
      "arriving\n",
      "liked\n",
      "disappointing\n",
      "managed\n",
      "served\n",
      "preparing\n",
      "loving\n",
      "liking\n",
      "reviewing\n",
      "venturing\n",
      "overpriced\n",
      "including\n",
      "during\n",
      "checked\n",
      "disappointed\n",
      "red\n",
      "decorated\n",
      "changing\n",
      "going\n",
      "served\n",
      "considering\n",
      "coming\n",
      "watched\n",
      "greeted\n",
      "seated\n",
      "waited\n",
      "flavored\n",
      "ordered\n",
      "going\n",
      "ordered\n",
      "everything\n",
      "relocated\n",
      "impressed\n",
      "seated\n",
      "priced\n",
      "looking\n",
      "treated\n",
      "ordered\n",
      "dressing\n",
      "used\n",
      "handed\n",
      "listed\n",
      "dining\n",
      "missed\n",
      "thrilled\n",
      "Everything\n",
      "amazing\n",
      "inspired\n",
      "judging\n",
      "desired\n",
      "maintaining\n",
      "asking\n",
      "overcooked\n",
      "decided\n",
      "looked\n",
      "having\n",
      "dressed\n",
      "treated\n",
      "something\n",
      "lacking\n",
      "ordered\n",
      "sucked\n",
      "expected\n",
      "sucked\n",
      "imagined\n",
      "Interesting\n",
      "served\n",
      "preparing\n",
      "arrived\n",
      "missing\n",
      "satisfied\n",
      "feeling\n",
      "voted\n",
      "insulted\n",
      "disrespected\n",
      "dreamed\n",
      "exceeding\n",
      "inviting\n",
      "lived\n",
      "stepped\n",
      "mixed\n",
      "showed\n",
      "climbing\n",
      "realized\n",
      "waiting\n",
      "coming\n",
      "loved\n",
      "being\n",
      "lacking\n",
      "needed\n",
      "going\n",
      "loved\n",
      "wrapped\n",
      "uninspired\n",
      "amazing\n",
      "dealing\n",
      "annoying\n",
      "Ordered\n",
      "uploaded\n",
      "falling\n",
      "covered\n",
      "sporting\n",
      "supposed\n",
      "amazing\n",
      "rolled\n",
      "stayed\n",
      "providing\n",
      "building\n",
      "lighting\n",
      "Based\n",
      "received\n",
      "going\n",
      "privileged\n",
      "nothing\n",
      "working\n",
      "eating\n",
      "dressing\n",
      "charged\n",
      "being\n",
      "visited\n",
      "proclaimed\n",
      "disappointed\n",
      "Stopped\n",
      "dedicated\n",
      "liked\n",
      "outstanding\n",
      "getting\n",
      "disappointed\n",
      "waited\n",
      "waited\n",
      "burned\n",
      "waited\n",
      "amazing\n",
      "disappointed\n",
      "Waited\n",
      "disappointed\n",
      "pulled\n",
      "prepared\n",
      "rating\n",
      "eating\n",
      "writing\n",
      "everything\n",
      "dining\n",
      "fried\n",
      "boring\n",
      "passed\n",
      "charming\n",
      "ordered\n",
      "toasted\n",
      "untoasted\n",
      "going\n",
      "figured\n",
      "making\n",
      "pricing\n",
      "considering\n",
      "returned\n",
      "amazing\n",
      "eyed\n",
      "disappointed\n",
      "pleased\n",
      "Everything\n",
      "replenished\n",
      "disappointed\n",
      "nothing\n",
      "nothing\n",
      "driving\n",
      "treated\n",
      "during\n",
      "evening\n",
      "offered\n",
      "tasted\n",
      "Outstanding\n",
      "buying\n",
      "handling\n",
      "wasting\n",
      "craving\n",
      "dropped\n",
      "decorated\n",
      "dining\n",
      "interesting\n",
      "amazing\n",
      "served\n",
      "being\n",
      "outshining\n",
      "starving\n",
      "coming\n",
      "walked\n",
      "stuffed\n",
      "located\n",
      "considering\n",
      "shopping\n",
      "nothing\n",
      "Cooked\n",
      "disappointed\n",
      "screwed\n",
      "getting\n",
      "frustrated\n",
      "iced\n",
      "stuffed\n",
      "disappointed\n",
      "trying\n",
      "grossed\n",
      "enjoyed\n",
      "eating\n",
      "going\n",
      "looked\n",
      "overwhelmed\n",
      "stayed\n",
      "everything\n",
      "smeared\n",
      "stepped\n",
      "tracked\n",
      "tried\n",
      "rushed\n",
      "loved\n",
      "Ordered\n",
      "Nothing\n",
      "cooked\n",
      "going\n",
      "insulted\n",
      "contained\n",
      "enjoyed\n",
      "relaxed\n",
      "loved\n",
      "outstanding\n",
      "running\n",
      "acknowledged\n",
      "forgetting\n",
      "upgrading\n",
      "trimmed\n",
      "cooked\n",
      "claimed\n",
      "handled\n",
      "asked\n",
      "eating\n",
      "bring\n",
      "hoping\n",
      "living\n",
      "limited\n",
      "boiled\n",
      "dining\n",
      "liked\n",
      "sliced\n",
      "attached\n",
      "humiliated\n",
      "filling\n",
      "fried\n",
      "amazing\n",
      "impressed\n",
      "disappointed\n",
      "priced\n",
      "Everything\n",
      "disappointed\n",
      "thing\n",
      "amazing\n",
      "need\n",
      "Everything\n",
      "need\n",
      "interesting\n",
      "experienced\n",
      "amazing\n",
      "amazing\n",
      "waited\n",
      "seated\n",
      "waiting\n",
      "going\n",
      "going\n",
      "decided\n",
      "dining\n",
      "pleased\n",
      "saving\n",
      "something\n",
      "trying\n",
      "disgusting\n",
      "hankering\n",
      "recommended\n",
      "helped\n",
      "being\n",
      "witnessed\n",
      "Waited\n",
      "waited\n",
      "waited\n",
      "checked\n",
      "tasted\n",
      "disappointed\n",
      "served\n",
      "being\n",
      "rated\n",
      "recommended\n",
      "pulled\n",
      "waited\n",
      "acknowledged\n",
      "being\n",
      "setting\n",
      "perpared\n",
      "dusted\n",
      "powdered\n",
      "enjoyed\n",
      "expanded\n",
      "ended\n",
      "arrived\n",
      "sitting\n",
      "waiting\n",
      "satisfying\n",
      "wanted\n",
      "disappointed\n",
      "eating\n",
      "need\n",
      "being\n",
      "freaking\n",
      "checked\n",
      "impressed\n",
      "reheated\n",
      "getting\n",
      "amazing\n",
      "tasted\n",
      "disappointing\n",
      "grilled\n",
      "seasoning\n",
      "going\n",
      "focused\n",
      "roasted\n",
      "asked\n",
      "ignored\n",
      "being\n",
      "bring\n",
      "letting\n",
      "tasted\n",
      "evening\n",
      "Ordered\n",
      "greeted\n",
      "seated\n",
      "Tried\n",
      "seated\n",
      "waiting\n",
      "being\n",
      "eating\n",
      "going\n",
      "Disappointed\n",
      "ordered\n",
      "constructed\n",
      "seating\n",
      "fried\n",
      "requested\n",
      "playing\n",
      "amazing\n",
      "staying\n",
      "used\n",
      "tasted\n",
      "giving\n",
      "talking\n",
      "amazing\n",
      "drenched\n",
      "amazing\n",
      "amazing\n",
      "tried\n",
      "walked\n",
      "expected\n",
      "disappointed\n",
      "amazing\n",
      "mortified\n",
      "filling\n",
      "dripping\n",
      "impressed\n",
      "going\n",
      "serving\n",
      "refrained\n",
      "recommending\n",
      "pleased\n",
      "thing\n",
      "reading\n",
      "loved\n",
      "grilled\n",
      "reminded\n",
      "seating\n",
      "sucked\n",
      "hooked\n",
      "ordered\n",
      "disappointed\n",
      "going\n",
      "everything\n",
      "seasoned\n",
      "added\n",
      "thing\n",
      "sitting\n",
      "waiting\n",
      "bring\n",
      "revisiting\n",
      "coming\n",
      "touched\n",
      "anything\n",
      "fried\n",
      "opened\n",
      "impressed\n",
      "feeling\n",
      "during\n",
      "watched\n",
      "thing\n",
      "being\n",
      "Tasted\n",
      "amazing\n",
      "being\n",
      "amazing\n",
      "ordered\n",
      "satifying\n",
      "describing\n",
      "coming\n",
      "everything\n",
      "received\n",
      "Paying\n",
      "going\n",
      "impressed\n",
      "overcooked\n",
      "cooked\n",
      "needed\n",
      "served\n",
      "ordered\n",
      "thing\n",
      "amazing\n",
      "overpriced\n",
      "packed\n",
      "getting\n",
      "opposed\n",
      "cramming\n",
      "priced\n",
      "surprised\n",
      "focused\n",
      "considering\n",
      "overpriced\n",
      "fucking\n",
      "tried\n",
      "enjoyed\n",
      "going\n",
      "qualified\n",
      "tasted\n",
      "hated\n",
      "appealing\n",
      "getting\n",
      "coming\n",
      "watched\n",
      "fried\n",
      "Everything\n",
      "dealing\n",
      "tried\n",
      "everything\n",
      "something\n",
      "during\n",
      "helped\n",
      "dining\n",
      "cooking\n",
      "dining\n",
      "started\n",
      "editing\n",
      "highlighted\n",
      "setting\n",
      "used\n",
      "amazing\n",
      "enjoyed\n",
      "ordered\n",
      "tasted\n",
      "asked\n",
      "refused\n",
      "tried\n",
      "rotating\n",
      "Pricing\n",
      "toasted\n",
      "satisfying\n",
      "anticipated\n",
      "disappointing\n",
      "amazing\n",
      "returning\n",
      "unexperienced\n",
      "running\n",
      "insulted\n",
      "disrespected\n",
      "being\n",
      "impressed\n",
      "puréed\n",
      "thing\n",
      "nothing\n",
      "poisoning\n",
      "thinking\n",
      "something\n",
      "going\n",
      "disgusting\n",
      "caring\n",
      "asked\n",
      "bring\n",
      "Disappointing\n",
      "rated\n",
      "saying\n",
      "going\n",
      "lacked\n",
      "coming\n",
      "sliced\n",
      "pulled\n",
      "building\n",
      "seating\n",
      "undercooked\n",
      "seemed\n",
      "watered\n",
      "dipping\n",
      "lacked\n",
      "disappointed\n",
      "overpriced\n",
      "setting\n",
      "ensued\n",
      "anything\n",
      "drinking\n",
      "serving\n",
      "disappointed\n",
      "placed\n",
      "avoided\n",
      "received\n",
      "wanted\n",
      "doing\n",
      "sucked\n",
      "happened\n",
      "putting\n",
      "owned\n",
      "wanted\n",
      "Overpriced\n",
      "getting\n",
      "vomited\n",
      "looking\n",
      "started\n",
      "coming\n",
      "unwrapped\n",
      "lacked\n",
      "seemed\n",
      "undercooked\n",
      "closed\n",
      "staying\n",
      "refried\n",
      "dried\n",
      "disappointed\n",
      "lacking\n",
      "impressed\n",
      "underwhelming\n",
      "wasted\n",
      "poured\n",
      "drawing\n",
      "bring\n"
     ]
    }
   ],
   "source": [
    "palabra_ed = []\n",
    "palabra_ing = []\n",
    "\n",
    "#Palabras que terminan en ing o ed\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      ing = re.findall(r'\\b\\w+ing\\b', linea)\n",
    "      ed = re.findall(r'\\b\\w+ed\\b', linea)\n",
    "\n",
    "      for palabra in ed:\n",
    "        palabra_ed.append(palabra)\n",
    "        print(palabra)\n",
    "\n",
    "      for palabra in ing:\n",
    "        palabra_ing.append(palabra)\n",
    "        print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1714330690883,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "AhGq6De2Mvyh",
    "outputId": "2ba4e8d1-08d8-422b-89e4-11d34c6fb193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de resultados encontrados: 614\n"
     ]
    }
   ],
   "source": [
    "#Número de palabras que terminan en ed o ing\n",
    "total = palabra_ed + palabra_ing\n",
    "print(\"Cantidad de resultados encontrados:\", len(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70StdqAZa9E9"
   },
   "source": [
    "#**Parte 3. Proceso de limpieza.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaDUFXHrMvX2"
   },
   "source": [
    "*   **Pregunta 13.**  \n",
    "\n",
    "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
    "\n",
    "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
    "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
    "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
    "\n",
    "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes.\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1714330770482,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "K3kQzPOPMx0w"
   },
   "outputs": [],
   "source": [
    "corpus_limpio = []\n",
    "\n",
    "with open(DIR, \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "      comentario_limpio = re.sub(r'[^a-zA-Z\\s]', '', linea).lower()      # Paso 1 y 2: Eliminación de signos de puntuación y caracteres especiales, y transformar a minúsculas\n",
    "      comentario_limpio = re.sub(r'\\s+', ' ', comentario_limpio).strip() # Paso 3: Eliminación de espacios en blanco adicionales\n",
    "      corpus_limpio.append(comentario_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1714330771607,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "mYEDlHSFMyJN",
    "outputId": "2d54e801-ac2f-4846-fcec-d9cd026bd5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow loved this place\n",
      "crust is not good\n",
      "not tasty and the texture was just nasty\n",
      "stopped by during the late may bank holiday off rick steve recommendation and loved it\n",
      "the selection on the menu was great and so were the prices\n",
      "now i am getting angry and i want my damn pho\n",
      "honeslty it didnt taste that fresh\n",
      "the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer\n",
      "the fries were great too\n",
      "a great touch\n"
     ]
    }
   ],
   "source": [
    "# Corpus limpio\n",
    "for i in range(10):\n",
    "    print(corpus_limpio[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZwEhg2lUSAX"
   },
   "source": [
    "*   **Pregunta 14.**  \n",
    "\n",
    "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus.\n",
    "\n",
    "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
    "\n",
    "Al terminar calcula el total de tokens obtenido en todo el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1714330839508,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "kbAL9-v0V-jx",
    "outputId": "c3e3a9f5-dcd1-4d13-c880-b68afe64b1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de tokens en todo el corpus: 10777\n"
     ]
    }
   ],
   "source": [
    "# Tokenización del corpus\n",
    "tokens = [comentario.split() for comentario in corpus_limpio]\n",
    "total_tokens = sum(len(comentario) for comentario in tokens)\n",
    "print(\"\\nTotal de tokens en todo el corpus:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFeu0OJ7WDPD"
   },
   "source": [
    "*   **Pregunta 15.**  \n",
    "\n",
    "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus.\n",
    "\n",
    "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
    "\n",
    "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
    "\n",
    "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
    "\n",
    "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1714330844685,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "6FP4FF3KXGxm"
   },
   "outputs": [],
   "source": [
    "# Considera la siguiente lista como tu conjunto de stopwords:\n",
    "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1714330903094,
     "user": {
      "displayName": "Salvador Martínez Morales",
      "userId": "12237356375275337736"
     },
     "user_tz": 360
    },
    "id": "CD8yjyq1ZrwY",
    "outputId": "753b70b1-0c65-4626-a3d1-54d1e66e81d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de tokens restantes en el corpus: 5776\n",
      "Número de tokens únicos en el vocabulario: 1941\n"
     ]
    }
   ],
   "source": [
    "# Eliminación de los stopwords de todo el corpus\n",
    "corpus_sin_stopwords = []\n",
    "for comentario in tokens:\n",
    "    comentario_sin_stopwords = [palabra for palabra in comentario if palabra not in mis_stopwords]\n",
    "    corpus_sin_stopwords.append(comentario_sin_stopwords)\n",
    "\n",
    "# Calcular el número total de tokens restantes en todo el corpus\n",
    "total_tokens_restantes = sum(len(comentario) for comentario in corpus_sin_stopwords)\n",
    "\n",
    "# Calcular el número de tokens únicos en todo el corpus\n",
    "vocabulario = set()\n",
    "for comentario in corpus_sin_stopwords:\n",
    "    vocabulario.update(comentario)\n",
    "tokens_unicos = len(vocabulario)\n",
    "\n",
    "print(\"Número total de tokens restantes en el corpus:\", total_tokens_restantes)\n",
    "print(\"Número de tokens únicos en el vocabulario:\", tokens_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDbKkuxRbLoX"
   },
   "source": [
    "*   **Comentarios**\n",
    "\n",
    "Incluye finalmente tus comentarios de la actividad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7fzbvqVbUGr"
   },
   "source": [
    "La limpieza de datos en el procesamiento de lenguaje natural (PLN) es como darle un baño al texto antes de analizarlo. Elimina lo que no es necesario y lo deja listo para ser comprendido por las máquinas. Al hacerlo:\n",
    "\n",
    "1.   Mejora la calidad del texto: Quita los errores y elementos innecesarios, como signos de puntuación o palabras comunes que no aportan mucho sentido.\n",
    "2.   Facilita encontrar lo importante: Al eliminar lo que distrae, es más fácil identificar las palabras clave o las ideas principales en el texto.\n",
    "3.   Hace todo más rápido y eficiente: Al reducir la cantidad de información, el análisis de grandes cantidades de texto se vuelve más rápido y menos complicado para las computadoras.\n",
    "4.   Facilita compartir y trabajar con el texto: Un texto limpio y bien organizado es más fácil de usar en diferentes programas y sistemas de PLN.\n",
    "\n",
    "En resumen, limpiar los datos es como preparar el terreno antes de sembrar; asegura que la información que se va a analizar esté clara, organizada y lista para ser procesada de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHaKw_6Ldbaf"
   },
   "source": [
    "##**Fin de la Actividad de la semana 2.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "759SG4TyfbUn",
    "Zj-h4drXD-X9",
    "BY6yifxscfrx",
    "k_ewoagic5jc",
    "70StdqAZa9E9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
